# âš¡ Quant Analytics App

A **real-time quantitative analytics platform** that streams, processes, and visualizes live cryptocurrency market data.  
Built using **FastAPI**, **Redis**, **MySQL**, and **Streamlit**, this project showcases a scalable three-tier architecture with a background data worker for continuous ingestion and analytics computation.

---

## ğŸ§  Overview

The Quant Analytics App continuously collects tick data from Binance WebSocket, aggregates it into OHLCV candles, computes key statistical metrics (like Z-score, Spread, and Rolling Correlation), and visualizes them live in a Streamlit dashboard.

### ğŸ¯ Core Features

- **Live Data Ingestion**: Streams raw tick data from Binance WebSocket.
- **Data Storage**: Persists tick and candlestick data in MySQL.
- **Analytics Engine**: Computes Hedge Ratio, Spread, Z-score, and Rolling Correlation.
- **Real-time Updates**: Uses Redis pub/sub to push live analytics instantly to clients.
- **Interactive Dashboard**: Streamlit frontend displays live charts and metrics.

---

## ğŸ—ï¸ Architecture

```

quant-analytics-app/
â”œâ”€â”€ backend/                        # FastAPI backend (Application Layer)
â”‚   â”œâ”€â”€ main.py                     # Entry point (FastAPI app setup)
â”‚   â”œâ”€â”€ config.py                   # Environment and configuration management
â”‚   â”œâ”€â”€ database.py                 # SQLAlchemy DB connection and ORM
â”‚   â”œâ”€â”€ schemas.py                  # Pydantic schemas for validation and response models
â”‚   â”œâ”€â”€ models.py                   # SQLAlchemy models (TickData, OHLCV1m, AnalyticsCache)
â”‚   â”œâ”€â”€ crud.py                     # Database query helpers
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ analytics.py            # Analytics calculations (Z-score, Spread, Corr, etc.)
â”‚   â”‚   â””â”€â”€ websocket_manager.py    # Active WebSocket client handler
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ historical_data.py      # REST endpoint for historical data
â”‚       â””â”€â”€ real_time.py            # WebSocket endpoint for live updates
â”‚
â”œâ”€â”€ data_worker/                    # Independent async data ingestion and analytics worker
â”‚   â”œâ”€â”€ worker_main.py              # Orchestrates ingestion and analytics tasks
â”‚   â”œâ”€â”€ ingestion_stream.py         # Connects to Binance WebSocket, stores raw ticks
â”‚   â”œâ”€â”€ data_processing.py          # Resampling to 1m OHLCV candles
â”‚   â””â”€â”€ live_cacher.py              # Publishes live metrics to Redis
â”‚
â”œâ”€â”€ frontend/                       # Streamlit frontend (Presentation Layer)
â”‚   â”œâ”€â”€ streamlit_app.py            # Dashboard UI and WebSocket listener
â”‚   â””â”€â”€ .streamlit/secrets.toml     # Backend API/WebSocket URLs and credentials
â”‚
â”œâ”€â”€ .env.example                    # Template for environment variables
â”œâ”€â”€ docker-compose.yml              # Optional: easy setup for MySQL, Redis, FastAPI, Worker
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # You are here
â””â”€â”€ ws_test.py                      # Simple WebSocket client for testing backend

````

---

## âš™ï¸ Technologies Used

| Layer | Technology | Role |
|:------|:------------|:-----|
| Frontend | **Streamlit** | Real-time dashboard for live data visualization |
| Backend | **FastAPI** | Serves REST and WebSocket APIs |
| Worker | **Async Python (Pandas, asyncio)** | Data ingestion, resampling, analytics |
| Database | **MySQL** | Persistent data store |
| Cache | **Redis** | Live analytics cache & pub/sub messaging |
| Environment | **WSL / Docker Compose** | Local dev environment |

---

## ğŸš€ Setup and Running Locally

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/sharvanich/quant-analytics-app.git
cd quant-analytics-app
````

### 2ï¸âƒ£ Create Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure Environment Variables

Copy `.env.example` â†’ `.env` and update:

```bash
MYSQL_HOST=127.0.0.1
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=yourpassword
MYSQL_DB=quant_data

REDIS_HOST=127.0.0.1
REDIS_PORT=6379
```

### 4ï¸âƒ£ Start MySQL and Redis

You can run them manually or use Docker Compose:

```bash
docker-compose up -d
```

### 5ï¸âƒ£ Initialize Database

Run the database models once:

```bash
python -m backend.models
python -m backend.create_tables
```

### 6ï¸âƒ£ Run the Backend (FastAPI)

```bash
uvicorn backend.main:app --reload
```

Backend runs on â†’ `http://127.0.0.1:8000`

### 7ï¸âƒ£ Run the Data Worker

In a new terminal:

```bash
python -m data_worker.worker_main.py
```

### 8ï¸âƒ£ Run the Frontend (Streamlit)

In another terminal:

```bash
cd frontend
streamlit run streamlit_app.py
```

Frontend runs on â†’ `http://localhost:8501`

---

## ğŸ§© Testing WebSocket Connection

If you want to verify live updates manually:

```bash
python ws_test.py
```

Then publish dummy data in Redis:

```bash
redis-cli
PUBLISH live_updates:btcusdt '{"symbol":"btcusdt","price":64000,"zscore":0.5,"spread":1.2,"corr":0.95}'
```

## ğŸ§  Design Highlights

1. **Decoupled Architecture**:

   * Worker handles ingestion + analytics.
   * FastAPI handles API and WebSocket.
   * Streamlit focuses purely on visualization.

2. **Redis Pub/Sub**:

   * Enables instant message passing without polling.

3. **Asynchronous Processing**:

   * Uses `asyncio` and `aioredis` for non-blocking performance.

4. **Scalable Components**:

   * Each module (worker, API, frontend) can be containerized and scaled independently.

```
